\documentclass[letterpaper,12pt,oneside]{article}
\usepackage[paperwidth=8.5in,paperheight=11in,top=1in,bottom=1in,left=1in,right=1in]{geometry}
\usepackage{setspace}
\usepackage[colorlinks=true,allcolors=Blue]{hyperref}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{indentfirst}
\usepackage{titlesec}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{rotating}
\usepackage{tabularx}
\usepackage{outlines}
\usepackage{lineno}
\usepackage{array}
\usepackage{times}
\usepackage{cleveref}
\usepackage{acronym}
\usepackage[position=t]{subfig}
\usepackage{paralist}
\usepackage[noae]{Sweave}
\usepackage{natbib}
\usepackage{array}
\usepackage{pdflscape}
\usepackage{bm}
\usepackage{showlabels}
\usepackage{outlines}
\bibpunct{(}{)}{,}{a}{}{,}

% page margins and section title formatting
\linespread{1.5}
\setlength{\footskip}{0.5in}
\titleformat*{\section}{\Large\bf\em}
\titleformat*{\subsection}{\singlespace\large\bf}
\titleformat*{\subsubsection}{\singlespace\normalsize\bf\em}
\titlespacing{\section}{0in}{0in}{0in}
\titlespacing{\subsection}{0in}{0in}{0in}
\titlespacing{\subsubsection}{0in}{0in}{0in}

% cleveref options
\crefname{table}{Table}{Tables}
\crefname{figure}{Fig.}{Figs.}
\renewcommand{\figurename}{Fig.}

% aliased citations
% \defcitealias{FLDEP12}{FLDEP 2012}

%acronyms
\acrodef{AIC}{Akaike Information Criterion}
\acrodef{ARIMA}{Autoregressive Integrated Moving Average}
\acrodef{GAM}{generalized additive models}
\acrodef{USGS}{US Geological Survey}
\acrodef{WRTDS}{weighted regression on time, discharge, and season}

%knitr options
<<setup,include=F,cache=F>>=
library(knitr)
opts_chunk$set(fig.path = 'figs/', fig.align = 'center', fig.show = 'hold', message = F, echo = F, results = 'asis', dev = 'pdf', dev.args = list(family = 'serif'), fig.pos = '!ht', warning = F)
options(replace.assign = TRUE, width = 90)
@

% get the version based on commit date
<<echo = FALSE, cache = FALSE>>=
raw <- system('git log -1', intern = TRUE)
raw <- raw[grep('^Date', raw)]
raw <- paste('Version', raw)
@

% R libs
<<echo = FALSE>>=
library(httr)
library(ggplot2)
library(dplyr)
library(scales)
library(wesanderson)
@

% get online bib file
<<echo = FALSE, cache = FALSE>>=
refs <- GET('https://raw.githubusercontent.com/fawda123/refs/master/refs.bib')
refs <- rawToChar(refs$content)
writeLines(refs, con = file('refs.bib'))
@

\begin{document}

\raggedbottom
% \linenumbers
\raggedright
\urlstyle{same}
\setlength{\parindent}{0.5in}
\renewcommand\refname{References \vspace{12pt}}

\begin{singlespace}
\title{{\bf {\Large Comparison of weighted regression and additive models for trend evaluation of water quality in tidal waters}}}
\author{
  {\bf {\normalsize Marcus W. Beck$^1$, Rebecca Murphy$^2$}}
  \\\\{\textit {\normalsize $^1$ORISE Research Participation Program}}
  \\{\textit {\normalsize USEPA National Health and Environmental Effects Research Laboratory}}
  \\{\textit {\normalsize Gulf Ecology Division, 1 Sabine Island Drive, Gulf Breeze, FL 32561}}
	\\{\textit {\normalsize Phone: 850-934-2480, Fax: 850-934-2401, Email: \href{mailto:beck.marcus@epa.gov}{beck.marcus@epa.gov}}}
  \\\\{\textit {\normalsize $^2$UMCES at Chesapeake Bay Program}}
	\\{\textit {\normalsize 410 Severn Avenue, Suite 112, Annapolis, MD 21403}}
	\\{\textit {\normalsize Phone: 410-267-9837, Fax: 410-267-5777, Email: \href{mailto:rmurphy@chesapeakbay.net}{rmurphy@chesapeakebay.net}}}
  \vspace{1in} 
  \\ \Sexpr{raw}
	}
\date{}
\maketitle
\end{singlespace}
\clearpage

\section*{Abstract}

\noindent \textit{Key words}:

\clearpage

\acresetall

\section{Introduction}

\begin{outline}
\0 \noindent Needs
\1 Quantitative tools that describe trends in water quality time series are needed to identify factors that influence ecosystem condition and to evaluate the effects of management activities in the context of multiple drivers
\1 Recent adaptation of statistical models for evaluating water quality time series have shown promise for application in tidal waters, specifically \ac{GAM} and \ac{WRTDS}
\1 These similar techniques can be used to quantify relationships between response measures and different drivers that may vary over time, in addition to an evaluation of trends independent of variation in freshwater inputs
\1 The relative merits of each approach have not been evaluated, particularly related to accuracy of the empirical description and the desired products for trend evaluation
\1 Such a comparison could inform the use of each model for addressing management or restoration needs or for developing more robust descriptions of long-term changes in ecosystem characteristics
\0 Goal: Provide a description of the relative abilities of \acp{GAM} and \ac{WRTDS} to describe long-term changes in time series of response endpoints in tidal waters \\
\0 \noindent Objectives:
\1 Provide a narrative comparison of the statistical foundation of each technique, both as a general description and as a means to evaluate water quality time series
\1 Use each technique to develop an empirical description of water quality changes in a common dataset with known historical changes in water quality drivers
\1 Apply the models to simulated data to evaluate ability of the models to describe true changes
\1 Compare each technique's ability to describe changes, as well as the differences in the information provided by each
\1 Provide recommendations on the most appropriate context for using each method
\end{outline}

\section{Methods}

\subsection{Study site}

The Patuxent River Estuary... background, history \\
Observed trends over time \\
longitudinal gradient from watershed to mainstem influences, LE1.2, TF1.6\\
Show plots of trends over time in observed data \\

\subsection{Model descriptions}

How, Similarities, differences, optimal smoothing

The selection of optimal model parameters is a challenge that represents a tradeoff between model precision and ability to generalize to novel datasets.  Weighted regression requires identifying optimal half-window widths, whereas \acp{GAM} requires identifying the optimal degrees of freedom for the smoothing parameter.  Overfitting a model with excessively small window widths or excessive degrees of freedom will minimize prediction error but prevent extrapolation of results to different datasets. Similarly, underfitting a model with large window widths or very few degrees of freedom will reduce precision but will improve the ability to generalize results to different datasets. From a statistical perspective, the optimal model parameters provide a balance between over- and under-fitting.  Both models use a form of cross-validation to identify model parameters that maximize the precision of model predictions with a novel dataset.   

The basic premise of cross-validation is to identify the optimal set of model parameters that minimize prediction error on a dataset that was not used to develop the model.  For \acp{GAM} \citep{Hastie90,Zuur12}...[insert GAMs methods]. Similarly, the tidal adaptation of \ac{WRTDS} used k-fold cross-validation to identify the optimal half-window widths. For a given set of half-window widhts, the dataset was separated into ten disjoint sets, such that ten models were evaluated for every combination of k - 1 training and remaining test datasets. That is, the training dataset for each fold was all k - 1 folds and the test dataset was the remaining fold, repeated k times. The average prediction error of the test datasets across k folds provided an indication of model performance for the given combination of half-window widths.  The optimum window widths were those that provided minimum errors on the test data.  Evaluating multiple combinations of window-widths can be computationally intensive. An optimization function was implemented in R  \citep{Byrd95,RDCT15} to more efficiently evaluate model parameters using a search algorithm.  Window widths were searched using the limited-memory modification of the BFGS quasi-Newton method that imposes upper and lower bounds for each parameter.  The chosen parameters were based on a selected convergence tolerance for the error minimization of the search algorithm.  

\subsection{Comparison of modelled trends}

Explanatory power of each method - explained variance/fit in the response, histograms of errors (see page 14 in Moyer) - we can test for significant differences in the errors using a two-sided t-test.  Also see page 24/25 in Moyer for average difference comparisons between methods. \\
Similarity of predictions - observed data, simple scatterplots, similarity coefficients, similarity by time periods, etc.\\
Indications of change - direction/magnitude of trends by different time periods

\subsection{Comparison of flow-normalized trends}

The relative abilities of each model to characterize flow or salinity-normalized trends in chlorophyll were evaluated using simulated datasets with known components.  This approach was used because the flow-independent component of chlorophyll is typically not observed in the raw data such that the true signal must be empirically estimated.  Accordingly, the ability of each model to isolate the flow-normalized trend cannot be evaluated with absolute certainty unless the true signal is known.  Simulated time series of observed chlrophyll ($Chl_{obs}$) were created as additive components related to flow ($Chl_{flo}$, analogous to salinity) and a flow-independent biological component of chlorophyll ($Chl_{bio}$):
\begin{equation} \label{chlsim}
Chl_{obs} = Chl_{flo} + Chl_{bio}
\end{equation}
The simulated time series were based on stochastic models derived from actual water quality measurements to ensure the statistical properties were comparable to existing datasets.  Daily flow observations were obtained from the \ac{USGS} stream gage station 01594440 near Bowie, Maryland (38$^{\circ}$57$'$21.3$''$N, 76$^{\circ}$41$'$37.3$''$W) from 1985 to 2014.  Daily chlorophyll records were obtained from the Jug Bay station (38$^{\circ}$46$'$50.6$''$N, 76$^{\circ}$42$'$29.1$''$W) of the Chesapeake Bay Maryland National Estuarine Research Reserve.  Daily chlorophyll concentrations were estimated from fluorescence values that did not include blue-green algae blooms.  Our primary concern was simulating chlorophyll concentrations at monthly or bimonthly timesteps such that taxa-specific concentrations on a daily time step were not relevant.

The statistical properties of both the flow and chlorophyll time series were characterized to create a stochastic model of water quality described in \cref{chlsim}.  This approach allowed us to evaluate the ability of \acp{GAM} and \ac{WRTDS} under different sampling regimes while ensuring the simulated datasets were consistent with the statistical properties of known time series at much finer temporal resolution.  The model consisted of four separate components: \begin{inparaenum}[1\upshape)]
\item stationary seasonal component of discharge,
\item serially-correlated error structure of the residuals from the seasonal discharge model, 
\item stationary seasonal component of chlorophyll independent of discharge, and
\item serially-correlated error structure of the residuals from the seasonal chlorophyll model.
\end{inparaenum}
First, daily flow data were simulated as the additive combination of a stationary seasonal component and serially-correlated errors:
\begin{equation} \label{qsim}
\ln\left(Q_{i}\right) = \beta_0 + \beta_1 \sin\left(2\pi T\right) + \beta_2 \cos\left(2\pi T\right) + \sigma\cdot\varepsilon
\end{equation}
creating a stationary seasonal regression of flow over $i$ of $n$ days in the record.  The residuals from this regression were used to estimate the error distribution using an \ac{ARIMA} model.  Parameters of the model were chosen using stepwise estimation for nonseasonal univariate time series that minimized \ac{AIC} to identify appropriate $p$ and $q$ coefficients as described in \citet{Hyndman08}.  The resulting model was used to generate random errors from a standard normal distribution for the length of the original time series.  The random, serially-correlated errors were multiplied by the standard deviation of the residuals and added to the seasonal component in \cref{qsim} to create a simulated, daily log-flow time series.  

The chlorophyll time series was created using a similar approach with minor differences.  The first step estimated the stationary seasonal component of the chlorophyll time series by fitting a \ac{WRTDS} model that explicitly included discharge using one year of data from the whole time series.  This approach was used to isolate an error structure for simulation that was independent of flow and biology, while assuming the seasonal component was strictly related to biological processes.  Although this is in invalid assumption for the true time series, the statistical properties of the resulting model were sufficient for creating simulated time series.  The error distribution was then estimated from the residuals as before using an \ac{ARIMA} estimate of the residual parameters.  Standard error estimates from the regression used at each point in the one-year time series were also retained for each residual.  Random errors using the estimated auto-regressive structures were simulated for the entire year and multiplied by the corresponding standard error estimate from the regression.  The entire year was repeated for every year in the observed time series.  All simulated errors were rescaled to the range of the original residuals that were used to estimate the distribution.  Finally, the simulated flow-component was added to the simulated chlorophyll time series to create a combined chlorophyll-flow time series in \cref{chlsim}.  

A daily time series for the entire period of record was simulated using the above methods and then used to create additional time series with different sampling frequencies and varying contributions of the flow component, $Chl_{flo}$, in \cref{chlsim}.  Monthly and bimonthly (twice a month) time series were created by sampling the original time series at appropriate intervals.  Additionally, varying contributions of the flow component on observed chlorophyll were evaluated by multiplying $Chl_{flo}$ by a vector of coefficients that represented the relative effect of flow through the time series at the given sampling frequency.  For example, an effect of flow on the time series that changes from non-existent to positive throughout the period of observation can be simulated by creating a vector ranging from zero to one with an increase at a chosen intermediate date.  $Chl_{flo}$ is centered at zero, multiplied by the chosen vector, and then added to $Chl_{bio}$ to create $Chl_{obs}$ at the given sampling frequency.

The relative abilities of \ac{WRTDS} and \acp{GAM} to evaluate flow-normalized trends were compared using time series that varied the sampling frequency and contribution of the flow component described above.  For monthly and bimonthly sampling frequencies, the contribution of the flow component to the observed time series varied from constant, non-existent, steadily increasing, and steadily decreasing.  Respectively, the vector of coefficients applied to each flow component was a constant vector of ones, a constant vector of zeroes, a logistic function starting at zero and ending at one, and a logistic function starting at one and ending at zero.  This created eight time series that were used to evaluate each model.  The flow-normalized results of each model were compared to each other and to the original biological chlorophyll time series of each simulated time series.   

\section{Results}

\begin{outline}
\0 \noindent Predictions with actual data \\
\0 \noindent Simulations
\end{outline}

\section{Discussion}

\begin{outline}
\0 \noindent Qualitative comparison
\1 Computational requirements and potential limitations
\1 Data needs or transferability of each technique to novel datasets
\1 Products, e.g., conditional quantiles of \ac{WRTDS}, confidence intervals for \acp{GAM}, handling censored data, hypothesis testing vs description
\1 Appropriate context for using each approach
\end{outline}

\subsection{Conclusions}

%%%%%%
% refs
\clearpage
\begin{singlespace}
\bibliographystyle{apalike_mine}
\bibliography{refs}
\end{singlespace}
\clearpage

%%%%%%
% tables

% site characteristics of TF16, LE12

% trend summary of WRTDS/GAMs (like table 4 in Beck and Hagy 2015, change as slope for diff time periods - p. 12 Moyer et al. 2012))

% performance summary of predictions WRTDS/GAMs - RMSE values for each, percent differences between the two, average differences as in eqn. 10 for Moyer  

% performance summary of flow-normalized predictions WRTDS/GAMs LE12, TF16 - RMSE values for each, percent differences between the two, average differences as in eqn. 10 for Moyer  

% performance summary of flow-normalized predictions WRTDS/GAMS simulated data - compare between the two mods as in previous fig, but also compare with 'known' flow-independet ts

% qualitative comparison of each mod, pros/cons of each, etc. to accompany discussion

%%%%%%
% figures

% study site map

<<chlyr, fig.width = 7, fig.height = 9, eval = T, echo = F, cache = T, fig.cap = 'Annual chlorophyll trends at each monitoring station in the Patuxent River Estuary.  Values are annual medians of ln-chlorophyll-a with size and color proportional between years.'>>=
load(file = 'data/pax_data.RData')
load(file = 'data/pax_meta.RData')
load(file = 'data/pax_clip.RData')

# color palette
cols <- wes_palette('Zissou', 100, 'continuous') %>% 
  as.character %>% 
  .[1:60]

# change default ggplot theme
theme_mine <- function (base_size = 12, base_family = "") {
  theme_bw(base_size = base_size, base_family = base_family) %+replace% 
  theme(
    axis.text.x = element_text(size = 8), 
    plot.background = element_rect(fill='transparent', 
      colour = NA),
    panel.background = element_rect(fill='transparent', 
      colour = NA),
    legend.background = element_rect(fill='transparent', 
      colour = NA),
    strip.background = element_rect(fill = 
        alpha(cols[length(cols)], 0.5)),
    legend.key = element_rect(fill = 'transparent', 
      colour = NA)
    )   
}
theme_set(theme_mine())

# color for water for continuity with last fig
wt_col <- wes_palette('Zissou', 100, 'continuous')[10] %>% 
  alpha(0.6)

# format pax_meta for mrg with pax_plo
pax_meta <- select(pax_meta, STATION, LONG, LAT) %>% 
  mutate(STATION = as.character(STATION))

# add month to pax data
pax_data <- mutate(pax_data, 
  mo = as.numeric(strftime(date, '%m')),
  yr = strftime(date, '%Y')
  ) %>% 
  mutate(STATION = as.character(STATION))

# get annual medians by station, add coords
pax_yr <- group_by(pax_data, STATION, yr) %>% 
  summarize(lnchla = median(lnchla, na.rm = T)) %>% 
  left_join(., pax_meta, by = 'STATION')

# add some rows to pax_yr for station labels
stat_add <- unique(pax_yr[, c('STATION', 'LONG', 'LAT')])
stat_add$yr <- 'Stations'
stat_add$lnchla <- NA
pax_yr <- rbind(pax_yr, stat_add)

# plot label
ylabs <- expression(paste('ln-Chl-',italic(a),' (',italic('\u03bc'),'g ',L^-1,')'))

# plot
ggplot(pax_meta, aes(x = LONG, y = LAT)) + 
  geom_polygon(data = pax_clip, aes(x = long, y = lat, group = group),
    fill = wt_col) +
  coord_map(
    xlim = c(-76.78, -76.36),
    ylim = c(38.27, 38.85)
  ) +
  # geom_text(data = yr_labs, aes(label = yr)) + 
  geom_point(data = pax_yr, aes(group = yr, size = lnchla, fill = lnchla), 
    pch = 21) +
  geom_text(data = pax_yr[pax_yr$yr == 'Stations', ], aes(label = STATION), size = 2) + 
  facet_wrap(~yr) +
  theme_mine() + 
  scale_size(range = c(1, 8)) + 
  scale_fill_gradientn(colours = cols) +
  theme(
    legend.position = 'top', 
    axis.title = element_blank(), 
    axis.text.y = element_text(size = 7),
    axis.text.x = element_text(size = 7, angle = 90, hjust = 1)
    ) + 
  guides(
    fill = guide_legend(title = ylabs), 
    size = guide_legend(title = ylabs)
    )

@

<<chlmo, fig.width = 7, fig.height = 7, eval = T, echo = F, cache = T, fig.cap = 'Monthly chlorophyll trends at each monitoring station in the Patuxent River Estuary.  Values are monthly medians of ln-chlorophyll-a with size and color proportional between months.'>>=
load(file = 'data/pax_data.RData')
load(file = 'data/pax_meta.RData')
load(file = 'data/pax_clip.RData')

# color palette
cols <- wes_palette('Zissou', 100, 'continuous') %>% 
  as.character %>% 
  .[1:60]

# change default ggplot theme
theme_mine <- function (base_size = 12, base_family = "") {
  theme_bw(base_size = base_size, base_family = base_family) %+replace% 
  theme(
    axis.text.x = element_text(size = 8), 
    plot.background = element_rect(fill='transparent', 
      colour = NA),
    panel.background = element_rect(fill='transparent', 
      colour = NA),
    legend.background = element_rect(fill='transparent', 
      colour = NA),
    strip.background = element_rect(fill = 
        alpha(cols[length(cols)], 0.5)),
    legend.key = element_rect(fill = 'transparent', 
      colour = NA)
    )   
}
theme_set(theme_mine())

# color for water for continuity with last fig
wt_col <- wes_palette('Zissou', 100, 'continuous')[10] %>% 
  alpha(0.6)

# format pax_meta for mrg with pax_plo
pax_meta <- select(pax_meta, STATION, LONG, LAT) %>% 
  mutate(STATION = as.character(STATION))

# add month to pax data
pax_data <- mutate(pax_data, 
  mo = as.numeric(strftime(date, '%m'))
  ) %>% 
  mutate(STATION = as.character(STATION))

# get annual medians by station, add coords
pax_mo <- group_by(pax_data, STATION, mo) %>% 
  summarize(lnchla = median(lnchla, na.rm = T)) %>% 
  left_join(., pax_meta, by = 'STATION')

# add some rows to pax_yr for station labels
stat_add <- unique(pax_yr[, c('STATION', 'LONG', 'LAT')])
stat_add$mo <- 'Stations'
stat_add$lnchla <- NA
pax_mo <- rbind(pax_mo, stat_add)

molevs <- c('January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 
  'November', 'December', 'Stations')
pax_mo$mo <- factor(pax_mo$mo, levels = c(1:12, 'Stations'), labels = molevs)

# plot label
ylabs <- expression(paste('ln-Chl-',italic(a),' (',italic('\u03bc'),'g ',L^-1,')'))

# plot
ggplot(pax_meta, aes(x = LONG, y = LAT)) + 
  geom_polygon(data = pax_clip, aes(x = long, y = lat, group = group),
    fill = wt_col) +
  coord_map(
    xlim = c(-76.78, -76.36),
    ylim = c(38.27, 38.85)
  ) +
  geom_point(data = pax_mo, aes(group = mo, size = lnchla, fill = lnchla), 
    pch = 21) +
  geom_text(data = pax_mo[pax_mo$mo == 'Stations', ], aes(label = STATION), size = 3) + 
  facet_wrap(~mo, ncol = 5) +
  theme_mine() + 
  scale_size(range = c(1, 8)) + 
  scale_fill_gradientn(colours = cols) +
  theme(
    legend.position = 'top', 
    axis.title = element_blank(), 
    axis.text.y = element_text(size = 7),
    axis.text.x = element_text(size = 7, angle = 90, hjust = 1)
    ) + 
  guides(
    fill = guide_legend(title = ylabs), 
    size = guide_legend(title = ylabs)
    )

@

% predicted trends for each mod - monthly time series of observed with predictions, RMSE in fig

% dynaplots for each mod (as in Fig. 8 Beck and Hagy 2015)

% scatterplot comparison of predictions between each mod (as in fig. 7 Moyer et al. 2012, incl ave diffs) - whole time series, different time periods (annual, seasonal groupings)

% histograms of errors for each mod, overlap with color transparencies - use period groupings as in previous fig

% examples of simulated datasets for eval of flow-normalization - daily, monthly, different flow effects

% results of flow-normalized data for simulations

\end{document}