\documentclass[letterpaper,12pt,oneside]{article}
\usepackage[paperwidth=8.5in,paperheight=11in,top=1in,bottom=1in,left=1in,right=1in]{geometry}
\usepackage{setspace}
\usepackage[colorlinks=true,allcolors=Blue]{hyperref}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{indentfirst}
\usepackage{titlesec}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{rotating}
\usepackage{tabularx}
\usepackage{outlines}
\usepackage{lineno}
\usepackage{array}
\usepackage{times}
\usepackage{cleveref}
\usepackage{acronym}
\usepackage[position=t]{subfig}
\usepackage{paralist}
\usepackage[noae]{Sweave}
\usepackage{natbib}
\usepackage{array}
\usepackage{pdflscape}
\usepackage{bm}
\usepackage{showlabels}
\usepackage{outlines}
\bibpunct{(}{)}{,}{a}{}{,}

% page margins and section title formatting
\linespread{1.5}
\setlength{\footskip}{0.5in}
\titleformat*{\section}{\Large\bf\em}
\titleformat*{\subsection}{\singlespace\large\bf}
\titleformat*{\subsubsection}{\singlespace\normalsize\bf\em}
\titlespacing{\section}{0in}{0in}{0in}
\titlespacing{\subsection}{0in}{0in}{0in}
\titlespacing{\subsubsection}{0in}{0in}{0in}

% cleveref options
\crefname{table}{Table}{Tables}
\crefname{figure}{Fig.}{Figs.}
\renewcommand{\figurename}{Fig.}

% aliased citations
% \defcitealias{FLDEP12}{FLDEP 2012}

%acronyms
\acrodef{GAM}{generalized additive models}
\acrodef{USGS}{US Geological Survey}
\acrodef{WRTDS}{weighted regression on time, discharge, and season}

%knitr options
<<setup,include=F,cache=F>>=
library(knitr)
opts_chunk$set(fig.path = 'figs/', fig.align = 'center', fig.show = 'hold', message = F, echo = F, results = 'asis', dev = 'pdf', dev.args = list(family = 'serif'), fig.pos = '!ht', warning = F)
options(replace.assign = TRUE, width = 90)
@

% get the version based on commit date
<<echo = FALSE, cache = FALSE>>=
raw <- system('git log -1', intern = TRUE)
raw <- raw[grep('^Date', raw)]
raw <- paste('Version', raw)
@

% R libs
<<echo = FALSE>>=
library(httr)
library(ggplot2)
library(dplyr)
library(scales)
library(wesanderson)
@

% get online bib file
<<echo = FALSE, cache = FALSE>>=
refs <- GET('https://raw.githubusercontent.com/fawda123/refs/master/refs.bib')
refs <- rawToChar(refs$content)
writeLines(refs, con = file('refs.bib'))
@

\begin{document}

\raggedbottom
% \linenumbers
\raggedright
\urlstyle{same}
\setlength{\parindent}{0.5in}
\renewcommand\refname{References \vspace{12pt}}

\begin{singlespace}
\title{{\bf {\Large Comparison of weighted regression and additive models for trend evaluation of water quality in tidal waters}}}
\author{
  {\bf {\normalsize Marcus W. Beck$^1$, Rebecca Murphy$^2$}}
  \\\\{\textit {\normalsize $^1$ORISE Research Participation Program}}
  \\{\textit {\normalsize USEPA National Health and Environmental Effects Research Laboratory}}
  \\{\textit {\normalsize Gulf Ecology Division, 1 Sabine Island Drive, Gulf Breeze, FL 32561}}
	\\{\textit {\normalsize Phone: 850-934-2480, Fax: 850-934-2401, Email: \href{mailto:beck.marcus@epa.gov}{beck.marcus@epa.gov}}}
  \\\\{\textit {\normalsize $^2$UMCES at Chesapeake Bay Program}}
	\\{\textit {\normalsize 410 Severn Avenue, Suite 112, Annapolis, MD 21403}}
	\\{\textit {\normalsize Phone: 410-267-9837, Fax: 410-267-5777, Email: \href{mailto:rmurphy@chesapeakbay.net}{rmurphy@chesapeakebay.net}}}
  \vspace{1in} 
  \\ \Sexpr{raw}
	}
\date{}
\maketitle
\end{singlespace}
\clearpage

\section*{Abstract}

\noindent \textit{Key words}:

\clearpage

\acresetall

\section{Introduction}

\begin{outline}
\0 Needs
\1 Quantitative tools that describe trends in water quality time series are needed to identify factors that influence ecosystem condition and to evaluate the effects of management activities in the context of multiple drivers
\1 Recent adaptation of statistical models for evaluating water quality time series have shown promise for application in tidal waters, specifically \ac{GAM} and \ac{WRTDS}
\1 These similar techniques can be used to quantify relationships between response measures and different drivers that may vary over time, in addition to an evaluation of trends independent of variation in freshwater inputs
\1 The relative merits of each approach have not been evaluated, particularly related to accuracy of the empirical description and the desired products for trend evaluation
\1 Such a comparison could inform the use of each model for addressing management or restoration needs or for developing more robust descriptions of long-term changes in ecosystem characteristics
\0 Goal: Provide a description of the relative abilities of \acp{GAM} and \ac{WRTDS} to describe long-term changes in time series of response endpoints in tidal waters
\0 Objectives:
\1 Provide a narrative comparison of the statistical foundation of each technique, both as a general description and as a means to evaluate water quality time series
\1 Use each technique to develop an empirical description of water quality changes in a common dataset with known historical changes in water quality drivers
\1 Apply the models to simulated data to evaluate ability of the models to describe true changes
\1 Compare each technique's ability to describe changes, as well as the differences in the information provided by each
\1 Provide recommendations on the most appropriate context for using each method
\end{outline}

\section{Methods}

\subsection{Study site}

The Patuxent River Estuary... \\
Observed trends over time \\
longitudinal gradient from watershed to mainstem influences, LE1.2, TF1.6\\
Show plots of trends over time in observed data \\

\subsection{Model descriptions}

How, Similarities, differences, optimal smoothing

The selection of optimal model parameters is a challenge that represents a tradeoff between model precision and ability to generalize to novel datasets.  Weighted regression requires identifying optimal half-window widths, whereas \ac{GAM} requires identifying the optimal degrees of freedom for the smoothing parameter.  Overfitting a model with excessively small window widths or too many degrees of freedom will minimize prediction error but prevent extrapolation of results to different datasets. Similarly, underfitting a model with large window widths or very few degrees of freedom will reduce precision but will improve the ability to generalize results to a different dataset. From a statistical perspective, the optimal smoothing provides a balance between over- and under-fitting.  Both models use a form of cross-validation to identify model parameters that maximize the precision of model predictions with a novel dataset.   

The basic premise of cross-validation is to identify the optimal set of model parameters that minimize prediction error on a dataset that was not used to develop the model.  For \acp{GAM} \citep{Hastie90,Zuur12}... Similarly, the tidal adaptation of \ac{WRTDS} used k-fold cross-validation to identify the optimal model parameters.  The dataset was separated into ten disjoint sets, such that ten models were evaluated for every combination of k - 1 training and remaining test datasets. That is, the training dataset for each fold was all k - 1 folds and the test dataset was the remaining fold, repeated k times. The average prediction error of the training datasets across k folds provides an indication of model performance for the given combination of half-window widths.  The optimum window widths were those that provided minimum errors on the test data.  Evaluating multiple combinations of window-widths can be computationally intensive. An optimization function was used to more efficiently evaluate model parameters using a search algorithm.  Window widths were searched using the limited-memory modification of the BFGS quasi-Newton method that imposes upper and lower bounds for each parameter \citep{Byrd95}.  The chosen parameters were based on a selected convergence tolerance for the error minimization of the search algorithm.  

\subsection{Comparison of modelled trends}

Explanatory power of each method - explained variance/fit in the response, histograms of errors (see page 14 in Moyer) - we can test for significant differences in the errors using a two-sided t-test.  Also see page 24/25 in Moyer for average difference comparisons between methods. \\
Similarity of predictions - observed data, simple scatterplots, similarity coefficients, similarity by time periods, etc.\\
Indications of change - direction/magnitude of trends by different time periods

\subsection{Comparison of flow-normalized trends}

The relative abilities of each model to characterize flow-normalized trends in chlorophyll were evaluated using simulated datasets with known components.  This approach was adopted because the flow-independent component of chlorophyll in estuaries cannot be known with absolute certainty.  Accordingly, the ability of each model to isolate the flow-normalized trend cannot be faithfully evaluted unless the true signal is known.  Simulated time series of observed chlrophyll ($Chl_{obs}$) were created as additive components related to flow ($Chl_{flo}$), a flow-indepenent biological component of chlorophyll ($Chl_{bio}$), and residual error ($\varepsilon$):
\begin{equation} \label{chlsim}
Chl_{obs} = Chl_{flo} + Chl_{bio} + \varepsilon
\end{equation}
The simulated time series were based on stochastic models derived from actual water quality measurements to ensure the statistical properties were similar to observed data.  Daily flow observations were obtained from the \ac{USGS} stream gage station 01594440 near Bowie, Maryland (38$^{\circ}$57$'$21.3$''$N, 76$^{\circ}$41$'$37.3$''$W) from 1985 to 2014.  Similarly, daily chloropyll records were obtained from the Jug Bay station (38$^{\circ}$46$'$50.6$''$N, 76$^{\circ}$42$'$29.1$''$W) of the Chesapeake Bay Maryland National Estuarine Research Reserve.  Daily chlorophyll concentrations were estimated from fluorescence values that did not include blue-green algae blooms.  However, our primarily concern was simulating chlorophyll concentrations at monthly or bimonthly timesteps such that taxa-specific concentrations on a daily time step were not relevant.

The statistical properties of both the flow and chlorophyll time series were characterized to create a stochastic model of water quality, where chlorophyll was directly related to the effects of flow.  This approach allowed us to evalute the ability of \acp{GAM} and \ac{WRTDS} under different sampling regimes while ensuring the simulated datasets were consistent with the statistical properties of known time series at much finer temporal resolution.  First, daily flow data were simulated as the additive combination of a stationary seasonal component and serially-correlated errors:
\begin{equation}
\ln\left(Q_{i}\right) = \beta_0 + \beta_1 \sin\left(2\pi T\right) + \beta_2 \cos\left(2\pi T\right) + \sigma\dot\varepsilon
\end{equation}
creating a stational seasonal regression of flow over time.  The residuals from this regression were used to estimate the error distribution using an auto-regressive, moving average model.  Results of this model were used to generate random errors from a standard normal distribution.  The random, serially-correlated errors were multiplied by the standard deviation of the residuals, then added to the seasonal component of original model to create a simulated, daily log-flow time series.  

The chlorophyll time series was created using a similar approach with minor differences.  The first step was to estimate the error component of the chlorophyll time series by fitting a \ac{WRTDS} model using one year of data from the whole time series.  This approach was used rather than a simple seasonal model to remove any confounding effect of flow on the error structure.  The error distribution was estimated from the residuals as before.  Standard error estimates from the regression used at each point in the one-year time series were also retained for each residual.  Random errors using the estimated auto-regressive structures were simulated for the entire year and multiplied by the corresponding standard error estimate from the regression.  The entire year was repeated for every year in the observed time series.  All simulated errors were rescaled to the range of the original residuals that were used to estimate the distribution.  

The simulated chlorophyll time series was then created by estimating the seasonal component from the observed time series, with the assumption that this component represented a flow-independent time series.  The chlorophyll error time series was then added to the seasonal model.  Finally, the simulated flow-component was added to the simulated chlorophyll time series to create a combined chlorophyll-flow time series.  The flow-component was first centered at zero and multiplied by a vector of coefficient that represented the relative effect of flow through the time series.  

Similarity of flow-normalized results - simulated data, simple scatterplots, similarity coefficients, similarity by time periods, etc.

\section{Results}

\begin{outline}
\0 Predicions with actual data
\0 Simulations
\end{outline}

\section{Discussion}

\begin{outline}
\0 Qualitative comparison
\1 Computational requirements and potential limitations
\1 Data needs or transferability of each technique to novel datasets
\1 Products, e.g., conditional quantiles of \ac{WRTDS}, confidence intervals for \acp{GAM}, handling censored data, hypothesis testing vs description
\1 Appropriate context for using each approach
\end{outline}

\subsection{Conclusions}

%%%%%%
% refs
\clearpage
\begin{singlespace}
\bibliographystyle{apalike_mine}
\bibliography{refs}
\end{singlespace}
\clearpage

%%%%%%
% tables

%%%%%%
% figures

%%%%%%
<<chlyr, fig.width = 7, fig.height = 9, eval = T, echo = F, cache = T, fig.cap = 'Annual chlorophyll trends at each monitoring station in the Patuxent River Estuary.  Values are annual medians of ln-chlorophyll-a with size and color proportional between years.'>>=
load(file = 'data/pax_data.RData')
load(file = 'data/pax_meta.RData')
load(file = 'data/pax_clip.RData')

# color palette
cols <- wes_palette('Zissou', 100, 'continuous') %>% 
  as.character %>% 
  .[1:60]

# change default ggplot theme
theme_mine <- function (base_size = 12, base_family = "") {
  theme_bw(base_size = base_size, base_family = base_family) %+replace% 
  theme(
    axis.text.x = element_text(size = 8), 
    plot.background = element_rect(fill='transparent', 
      colour = NA),
    panel.background = element_rect(fill='transparent', 
      colour = NA),
    legend.background = element_rect(fill='transparent', 
      colour = NA),
    strip.background = element_rect(fill = 
        alpha(cols[length(cols)], 0.5)),
    legend.key = element_rect(fill = 'transparent', 
      colour = NA)
    )   
}
theme_set(theme_mine())

# color for water for continuity with last fig
wt_col <- wes_palette('Zissou', 100, 'continuous')[10] %>% 
  alpha(0.6)

# format pax_meta for mrg with pax_plo
pax_meta <- select(pax_meta, STATION, LONG, LAT) %>% 
  mutate(STATION = as.character(STATION))

# add month to pax data
pax_data <- mutate(pax_data, 
  mo = as.numeric(strftime(date, '%m')),
  yr = strftime(date, '%Y')
  ) %>% 
  mutate(STATION = as.character(STATION))

# get annual medians by station, add coords
pax_yr <- group_by(pax_data, STATION, yr) %>% 
  summarize(lnchla = median(lnchla, na.rm = T)) %>% 
  left_join(., pax_meta, by = 'STATION')

# add some rows to pax_yr for station labels
stat_add <- unique(pax_yr[, c('STATION', 'LONG', 'LAT')])
stat_add$yr <- 'Stations'
stat_add$lnchla <- NA
pax_yr <- rbind(pax_yr, stat_add)

# plot label
ylabs <- expression(paste('ln-Chl-',italic(a),' (',italic('\u03bc'),'g ',L^-1,')'))

# plot
ggplot(pax_meta, aes(x = LONG, y = LAT)) + 
  geom_polygon(data = pax_clip, aes(x = long, y = lat, group = group),
    fill = wt_col) +
  coord_map(
    xlim = c(-76.78, -76.36),
    ylim = c(38.27, 38.85)
  ) +
  # geom_text(data = yr_labs, aes(label = yr)) + 
  geom_point(data = pax_yr, aes(group = yr, size = lnchla, fill = lnchla), 
    pch = 21) +
  geom_text(data = pax_yr[pax_yr$yr == 'Stations', ], aes(label = STATION), size = 2) + 
  facet_wrap(~yr) +
  theme_mine() + 
  scale_size(range = c(1, 8)) + 
  scale_fill_gradientn(colours = cols) +
  theme(
    legend.position = 'top', 
    axis.title = element_blank(), 
    axis.text.y = element_text(size = 7),
    axis.text.x = element_text(size = 7, angle = 90, hjust = 1)
    ) + 
  guides(
    fill = guide_legend(title = ylabs), 
    size = guide_legend(title = ylabs)
    )

@

<<chlmo, fig.width = 7, fig.height = 7, eval = T, echo = F, cache = T, fig.cap = 'Monthly chlorophyll trends at each monitoring station in the Patuxent River Estuary.  Values are monthly medians of ln-chlorophyll-a with size and color proportional between months.'>>=
load(file = 'data/pax_data.RData')
load(file = 'data/pax_meta.RData')
load(file = 'data/pax_clip.RData')

# color palette
cols <- wes_palette('Zissou', 100, 'continuous') %>% 
  as.character %>% 
  .[1:60]

# change default ggplot theme
theme_mine <- function (base_size = 12, base_family = "") {
  theme_bw(base_size = base_size, base_family = base_family) %+replace% 
  theme(
    axis.text.x = element_text(size = 8), 
    plot.background = element_rect(fill='transparent', 
      colour = NA),
    panel.background = element_rect(fill='transparent', 
      colour = NA),
    legend.background = element_rect(fill='transparent', 
      colour = NA),
    strip.background = element_rect(fill = 
        alpha(cols[length(cols)], 0.5)),
    legend.key = element_rect(fill = 'transparent', 
      colour = NA)
    )   
}
theme_set(theme_mine())

# color for water for continuity with last fig
wt_col <- wes_palette('Zissou', 100, 'continuous')[10] %>% 
  alpha(0.6)

# format pax_meta for mrg with pax_plo
pax_meta <- select(pax_meta, STATION, LONG, LAT) %>% 
  mutate(STATION = as.character(STATION))

# add month to pax data
pax_data <- mutate(pax_data, 
  mo = as.numeric(strftime(date, '%m'))
  ) %>% 
  mutate(STATION = as.character(STATION))

# get annual medians by station, add coords
pax_mo <- group_by(pax_data, STATION, mo) %>% 
  summarize(lnchla = median(lnchla, na.rm = T)) %>% 
  left_join(., pax_meta, by = 'STATION')

# add some rows to pax_yr for station labels
stat_add <- unique(pax_yr[, c('STATION', 'LONG', 'LAT')])
stat_add$mo <- 'Stations'
stat_add$lnchla <- NA
pax_mo <- rbind(pax_mo, stat_add)

molevs <- c('January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 
  'November', 'December', 'Stations')
pax_mo$mo <- factor(pax_mo$mo, levels = c(1:12, 'Stations'), labels = molevs)

# plot label
ylabs <- expression(paste('ln-Chl-',italic(a),' (',italic('\u03bc'),'g ',L^-1,')'))

# plot
ggplot(pax_meta, aes(x = LONG, y = LAT)) + 
  geom_polygon(data = pax_clip, aes(x = long, y = lat, group = group),
    fill = wt_col) +
  coord_map(
    xlim = c(-76.78, -76.36),
    ylim = c(38.27, 38.85)
  ) +
  geom_point(data = pax_mo, aes(group = mo, size = lnchla, fill = lnchla), 
    pch = 21) +
  geom_text(data = pax_mo[pax_mo$mo == 'Stations', ], aes(label = STATION), size = 3) + 
  facet_wrap(~mo, ncol = 5) +
  theme_mine() + 
  scale_size(range = c(1, 8)) + 
  scale_fill_gradientn(colours = cols) +
  theme(
    legend.position = 'top', 
    axis.title = element_blank(), 
    axis.text.y = element_text(size = 7),
    axis.text.x = element_text(size = 7, angle = 90, hjust = 1)
    ) + 
  guides(
    fill = guide_legend(title = ylabs), 
    size = guide_legend(title = ylabs)
    )

@



\end{document}